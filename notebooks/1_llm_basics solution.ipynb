{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Tokenizers\n",
    "\n",
    "### 1.1 What is a tokenizer?\n",
    "\n",
    "A tokenizer is a tool that breaks down text into smaller units, called tokens, which can be words, subwords, or characters. This process helps in preparing the text for further analysis or processing by language models.\n",
    "\n",
    "![](../obsidian/Excalidraw/Tokenizers.svg)\n",
    "\n",
    "### 1.2 Locating Pre-Trained Tokenizers\n",
    "\n",
    "You can find the appropriate tokenizers for each open-source LLM in the [Hugging Face model hub](https://huggingface.co/models).\n",
    "\n",
    "For instance, to download the tokenizer for the [Deepseek R1](https://huggingface.co/deepseek-ai/DeepSeek-R1) model, simply use the following code:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs: [2337, 344, 260, 6810]\n",
      "Tokens: ['This', 'Ġis', 'Ġa', 'Ġsample']\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "# Download tokenizer from Hugging Face\n",
    "tokenizer = Tokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1\")\n",
    "\n",
    "# Encode a sample text\n",
    "tokens = tokenizer.encode(\"This is a sample\")\n",
    "print(f\"IDs: {tokens.ids}\")\n",
    "print(f\"Tokens: {tokens.tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Tokenizers and Languages\n",
    "\n",
    "It's important to note that tokenizers are typically developed before the model's training process, using only a subset of the available data. As a result, each model comes with its own unique \"vocabulary.\"\n",
    "\n",
    "This means that tokenizers may perform significantly worse when processing languages or text types that were not included in the training data.\n",
    "\n",
    "Below, we explore several tokenizers:\n",
    "\n",
    "- [`deepseek-ai/DeepSeek-R1`](https://huggingface.co/deepseek-ai/DeepSeek-R1)\n",
    "- [`google-bert/bert-base-uncased`](https://huggingface.co/google-bert/bert-base-uncased)\n",
    "- [`deepseek-ai/DeepSeek-Coder-V2-Instruct`](https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Instruct)\n",
    "- [`intfloat/multilingual-e5-large`](https://huggingface.co/intfloat/multilingual-e5-large)\n",
    "\n",
    "The code below visualizes these tokenizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: white; padding: 20px;\"><h3 style=\"color: #3366cc; font-family: Arial, sans-serif;\">deepseek-ai/DeepSeek-R1</h3><span style=\"color: black; background-color: hsl(72.46830940246582, 74%, 84%); padding: 2px;\">This</span> <span style=\"color: black; background-color: hsl(81.51293277740479, 76%, 86%); padding: 2px;\">is</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\">a</span> <span style=\"color: black; background-color: hsl(54.37910556793213, 70%, 80%); padding: 2px;\">sample</span> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: white; padding: 20px;\"><h3 style=\"color: #3366cc; font-family: Arial, sans-serif;\">google-bert/bert-base-uncased</h3><span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\">[CLS]</span> <span style=\"color: black; background-color: hsl(81.51293277740479, 76%, 86%); padding: 2px;\">this</span> <span style=\"color: black; background-color: hsl(90.55755615234375, 78%, 88%); padding: 2px;\">is</span> <span style=\"color: black; background-color: hsl(99.60213661193848, 80%, 90%); padding: 2px;\">a</span> <span style=\"color: black; background-color: hsl(72.46830940246582, 74%, 84%); padding: 2px;\">sample</span> <span style=\"color: black; background-color: hsl(54.37910556793213, 70%, 80%); padding: 2px;\">[SEP]</span> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: white; padding: 20px;\"><h3 style=\"color: #3366cc; font-family: Arial, sans-serif;\">deepseek-ai/DeepSeek-Coder-V2-Instruct</h3><span style=\"color: black; background-color: hsl(72.46830940246582, 74%, 84%); padding: 2px;\">This</span> <span style=\"color: black; background-color: hsl(81.51293277740479, 76%, 86%); padding: 2px;\">is</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\">a</span> <span style=\"color: black; background-color: hsl(54.37910556793213, 70%, 80%); padding: 2px;\">sample</span> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: white; padding: 20px;\"><h3 style=\"color: #3366cc; font-family: Arial, sans-serif;\">intfloat/multilingual-e5-large</h3><span style=\"color: black; background-color: hsl(54.37910556793213, 70%, 80%); padding: 2px;\"><s></span> <span style=\"color: black; background-color: hsl(81.51293277740479, 76%, 86%); padding: 2px;\">▁This</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\">▁is</span> <span style=\"color: black; background-color: hsl(99.60213661193848, 80%, 90%); padding: 2px;\">▁a</span> <span style=\"color: black; background-color: hsl(72.46830940246582, 74%, 84%); padding: 2px;\">▁sample</span> <span style=\"color: black; background-color: hsl(90.55755615234375, 78%, 88%); padding: 2px;\"></s></span> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import visualize_tokens\n",
    "\n",
    "visualize_tokens(\"This is a sample\", tokenizer_name=\"deepseek-ai/DeepSeek-R1\")\n",
    "visualize_tokens(\"This is a sample\", tokenizer_name=\"google-bert/bert-base-uncased\")\n",
    "visualize_tokens(\"This is a sample\", tokenizer_name=\"deepseek-ai/DeepSeek-Coder-V2-Instruct\")\n",
    "visualize_tokens(\"This is a sample\", tokenizer_name=\"intfloat/multilingual-e5-large\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Your Task:\n",
    "\n",
    "Determine which tokenizer was trained on German texts and which was not. Then, perform the same analysis for code as text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the tokenizers using a variety of German texts to identify which model has been trained on German data.\n",
    "# Likewise, test the tokenizers on code samples to determine which model effectively handles code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: white; padding: 20px;\"><h3 style=\"color: #3366cc; font-family: Arial, sans-serif;\">deepseek-ai/DeepSeek-R1</h3><span style=\"color: black; background-color: hsl(72.46830940246582, 74%, 84%); padding: 2px;\">class</span> <span style=\"color: black; background-color: hsl(54.37910556793213, 70%, 80%); padding: 2px;\">Foo</span> <span style=\"color: black; background-color: hsl(126.73596382141113, 65%, 75%); padding: 2px;\">():Ċ</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\"></span> <span style=\"color: black; background-color: hsl(81.51293277740479, 76%, 86%); padding: 2px;\">def</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\"></span> <span style=\"color: black; background-color: hsl(117.6913833618164, 63%, 73%); padding: 2px;\">__</span> <span style=\"color: black; background-color: hsl(108.64675998687744, 61%, 71%); padding: 2px;\">int</span> <span style=\"color: black; background-color: hsl(99.60213661193848, 80%, 90%); padding: 2px;\">__(</span> <span style=\"color: black; background-color: hsl(90.55755615234375, 78%, 88%); padding: 2px;\">self</span> <span style=\"color: black; background-color: hsl(153.86983394622803, 71%, 81%); padding: 2px;\">):Ċ</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\"></span> <span style=\"color: black; background-color: hsl(144.82521057128906, 69%, 79%); padding: 2px;\">pass</span> <span style=\"color: black; background-color: hsl(135.7805871963501, 67%, 77%); padding: 2px;\">Ċ</span> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: white; padding: 20px;\"><h3 style=\"color: #3366cc; font-family: Arial, sans-serif;\">google-bert/bert-base-uncased</h3><span style=\"color: black; background-color: hsl(90.55755615234375, 78%, 88%); padding: 2px;\">[CLS]</span> <span style=\"color: black; background-color: hsl(72.46830940246582, 74%, 84%); padding: 2px;\">class</span> <span style=\"color: black; background-color: hsl(144.82521057128906, 69%, 79%); padding: 2px;\">foo</span> <span style=\"color: black; background-color: hsl(135.7805871963501, 67%, 77%); padding: 2px;\">(</span> <span style=\"color: black; background-color: hsl(117.6913833618164, 63%, 73%); padding: 2px;\">)</span> <span style=\"color: black; background-color: hsl(99.60213661193848, 80%, 90%); padding: 2px;\">:</span> <span style=\"color: black; background-color: hsl(54.37910556793213, 70%, 80%); padding: 2px;\">def</span> <span style=\"color: black; background-color: hsl(126.73596382141113, 65%, 75%); padding: 2px;\">_</span> <span style=\"color: black; background-color: hsl(126.73596382141113, 65%, 75%); padding: 2px;\">_</span> <span style=\"color: black; background-color: hsl(108.64675998687744, 61%, 71%); padding: 2px;\">int</span> <span style=\"color: black; background-color: hsl(126.73596382141113, 65%, 75%); padding: 2px;\">_</span> <span style=\"color: black; background-color: hsl(126.73596382141113, 65%, 75%); padding: 2px;\">_</span> <span style=\"color: black; background-color: hsl(135.7805871963501, 67%, 77%); padding: 2px;\">(</span> <span style=\"color: black; background-color: hsl(81.51293277740479, 76%, 86%); padding: 2px;\">self</span> <span style=\"color: black; background-color: hsl(117.6913833618164, 63%, 73%); padding: 2px;\">)</span> <span style=\"color: black; background-color: hsl(99.60213661193848, 80%, 90%); padding: 2px;\">:</span> <span style=\"color: black; background-color: hsl(153.86983394622803, 71%, 81%); padding: 2px;\">pass</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\">[SEP]</span> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: white; padding: 20px;\"><h3 style=\"color: #3366cc; font-family: Arial, sans-serif;\">deepseek-ai/DeepSeek-Coder-V2-Instruct</h3><span style=\"color: black; background-color: hsl(72.46830940246582, 74%, 84%); padding: 2px;\">class</span> <span style=\"color: black; background-color: hsl(54.37910556793213, 70%, 80%); padding: 2px;\">Foo</span> <span style=\"color: black; background-color: hsl(135.7805871963501, 67%, 77%); padding: 2px;\">():</span> <span style=\"color: black; background-color: hsl(144.82521057128906, 69%, 79%); padding: 2px;\">Ċ</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\"></span> <span style=\"color: black; background-color: hsl(81.51293277740479, 76%, 86%); padding: 2px;\">def</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\"></span> <span style=\"color: black; background-color: hsl(126.73596382141113, 65%, 75%); padding: 2px;\">__</span> <span style=\"color: black; background-color: hsl(117.6913833618164, 63%, 73%); padding: 2px;\">int</span> <span style=\"color: black; background-color: hsl(108.64675998687744, 61%, 71%); padding: 2px;\">__(</span> <span style=\"color: black; background-color: hsl(99.60213661193848, 80%, 90%); padding: 2px;\">self</span> <span style=\"color: black; background-color: hsl(90.55755615234375, 78%, 88%); padding: 2px;\">):</span> <span style=\"color: black; background-color: hsl(144.82521057128906, 69%, 79%); padding: 2px;\">Ċ</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\"></span> <span style=\"color: black; background-color: hsl(153.86983394622803, 71%, 81%); padding: 2px;\">pass</span> <span style=\"color: black; background-color: hsl(144.82521057128906, 69%, 79%); padding: 2px;\">Ċ</span> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: white; padding: 20px;\"><h3 style=\"color: #3366cc; font-family: Arial, sans-serif;\">intfloat/multilingual-e5-large</h3><span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\"><s></span> <span style=\"color: black; background-color: hsl(99.60213661193848, 80%, 90%); padding: 2px;\">▁class</span> <span style=\"color: black; background-color: hsl(90.55755615234375, 78%, 88%); padding: 2px;\">▁Fo</span> <span style=\"color: black; background-color: hsl(126.73596382141113, 65%, 75%); padding: 2px;\">o</span> <span style=\"color: black; background-color: hsl(171.95903778076172, 75%, 85%); padding: 2px;\">(</span> <span style=\"color: black; background-color: hsl(72.46830940246582, 74%, 84%); padding: 2px;\">):</span> <span style=\"color: black; background-color: hsl(108.64675998687744, 61%, 71%); padding: 2px;\">▁de</span> <span style=\"color: black; background-color: hsl(81.51293277740479, 76%, 86%); padding: 2px;\">f</span> <span style=\"color: black; background-color: hsl(144.82521057128906, 69%, 79%); padding: 2px;\">▁__</span> <span style=\"color: black; background-color: hsl(153.86983394622803, 71%, 81%); padding: 2px;\">int</span> <span style=\"color: black; background-color: hsl(162.91441440582275, 73%, 83%); padding: 2px;\">__</span> <span style=\"color: black; background-color: hsl(171.95903778076172, 75%, 85%); padding: 2px;\">(</span> <span style=\"color: black; background-color: hsl(117.6913833618164, 63%, 73%); padding: 2px;\">self</span> <span style=\"color: black; background-color: hsl(72.46830940246582, 74%, 84%); padding: 2px;\">):</span> <span style=\"color: black; background-color: hsl(54.37910556793213, 70%, 80%); padding: 2px;\">▁pass</span> <span style=\"color: black; background-color: hsl(135.7805871963501, 67%, 77%); padding: 2px;\"></s></span> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "code = \"\"\"class Foo():\n",
    "    def  __int__(self):\n",
    "        pass\n",
    "\"\"\"\n",
    "\n",
    "visualize_tokens(code, tokenizer_name=\"deepseek-ai/DeepSeek-R1\")\n",
    "visualize_tokens(code, tokenizer_name=\"google-bert/bert-base-uncased\")\n",
    "visualize_tokens(code, tokenizer_name=\"deepseek-ai/DeepSeek-Coder-V2-Instruct\")\n",
    "visualize_tokens(code, tokenizer_name=\"intfloat/multilingual-e5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: white; padding: 20px;\"><h3 style=\"color: #3366cc; font-family: Arial, sans-serif;\">deepseek-ai/DeepSeek-R1</h3><span style=\"color: black; background-color: hsl(108.64675998687744, 61%, 71%); padding: 2px;\">Die</span> <span style=\"color: black; background-color: hsl(135.7805871963501, 67%, 77%); padding: 2px;\">einz</span> <span style=\"color: black; background-color: hsl(171.95903778076172, 75%, 85%); padding: 2px;\">ige</span> <span style=\"color: black; background-color: hsl(153.86983394622803, 71%, 81%); padding: 2px;\">Weis</span> <span style=\"color: black; background-color: hsl(81.51293277740479, 76%, 86%); padding: 2px;\">heit</span> <span style=\"color: black; background-color: hsl(190.0482416152954, 79%, 89%); padding: 2px;\">,</span> <span style=\"color: black; background-color: hsl(90.55755615234375, 78%, 88%); padding: 2px;\">die</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\">man</span> <span style=\"color: black; background-color: hsl(144.82521057128906, 69%, 79%); padding: 2px;\">wirklich</span> <span style=\"color: black; background-color: hsl(181.00366115570068, 77%, 87%); padding: 2px;\">bes</span> <span style=\"color: black; background-color: hsl(99.60213661193848, 80%, 90%); padding: 2px;\">it</span> <span style=\"color: black; background-color: hsl(199.09286499023438, 60%, 70%); padding: 2px;\">zt</span> <span style=\"color: black; background-color: hsl(190.0482416152954, 79%, 89%); padding: 2px;\">,</span> <span style=\"color: black; background-color: hsl(162.91441440582275, 73%, 83%); padding: 2px;\">ist</span> <span style=\"color: black; background-color: hsl(90.55755615234375, 78%, 88%); padding: 2px;\">die</span> <span style=\"color: black; background-color: hsl(190.0482416152954, 79%, 89%); padding: 2px;\">,</span> <span style=\"color: black; background-color: hsl(90.55755615234375, 78%, 88%); padding: 2px;\">die</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\">man</span> <span style=\"color: black; background-color: hsl(54.37910556793213, 70%, 80%); padding: 2px;\">anderen</span> <span style=\"color: black; background-color: hsl(208.13748836517334, 62%, 72%); padding: 2px;\">verm</span> <span style=\"color: black; background-color: hsl(126.73596382141113, 65%, 75%); padding: 2px;\">itt</span> <span style=\"color: black; background-color: hsl(117.6913833618164, 63%, 73%); padding: 2px;\">elt</span> <span style=\"color: black; background-color: hsl(72.46830940246582, 74%, 84%); padding: 2px;\">.</span> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: white; padding: 20px;\"><h3 style=\"color: #3366cc; font-family: Arial, sans-serif;\">google-bert/bert-base-uncased</h3><span style=\"color: black; background-color: hsl(108.64675998687744, 61%, 71%); padding: 2px;\">[CLS]</span> <span style=\"color: black; background-color: hsl(262.40514278411865, 74%, 84%); padding: 2px;\">die</span> <span style=\"color: black; background-color: hsl(289.5389699935913, 80%, 90%); padding: 2px;\">ein</span> <span style=\"color: black; background-color: hsl(144.82521057128906, 69%, 79%); padding: 2px;\">##zi</span> <span style=\"color: black; background-color: hsl(171.95903778076172, 75%, 85%); padding: 2px;\">##ge</span> <span style=\"color: black; background-color: hsl(226.22669219970703, 66%, 76%); padding: 2px;\">wei</span> <span style=\"color: black; background-color: hsl(235.271315574646, 68%, 78%); padding: 2px;\">##sh</span> <span style=\"color: black; background-color: hsl(126.73596382141113, 65%, 75%); padding: 2px;\">##eit</span> <span style=\"color: black; background-color: hsl(90.55755615234375, 78%, 88%); padding: 2px;\">,</span> <span style=\"color: black; background-color: hsl(262.40514278411865, 74%, 84%); padding: 2px;\">die</span> <span style=\"color: black; background-color: hsl(244.31593894958496, 70%, 80%); padding: 2px;\">man</span> <span style=\"color: black; background-color: hsl(271.4497661590576, 76%, 86%); padding: 2px;\">wi</span> <span style=\"color: black; background-color: hsl(280.49434661865234, 78%, 88%); padding: 2px;\">##rk</span> <span style=\"color: black; background-color: hsl(135.7805871963501, 67%, 77%); padding: 2px;\">##lich</span> <span style=\"color: black; background-color: hsl(54.37910556793213, 70%, 80%); padding: 2px;\">be</span> <span style=\"color: black; background-color: hsl(181.00366115570068, 77%, 87%); padding: 2px;\">##sit</span> <span style=\"color: black; background-color: hsl(208.13748836517334, 62%, 72%); padding: 2px;\">##z</span> <span style=\"color: black; background-color: hsl(162.91441440582275, 73%, 83%); padding: 2px;\">##t</span> <span style=\"color: black; background-color: hsl(90.55755615234375, 78%, 88%); padding: 2px;\">,</span> <span style=\"color: black; background-color: hsl(153.86983394622803, 71%, 81%); padding: 2px;\">ist</span> <span style=\"color: black; background-color: hsl(262.40514278411865, 74%, 84%); padding: 2px;\">die</span> <span style=\"color: black; background-color: hsl(90.55755615234375, 78%, 88%); padding: 2px;\">,</span> <span style=\"color: black; background-color: hsl(262.40514278411865, 74%, 84%); padding: 2px;\">die</span> <span style=\"color: black; background-color: hsl(244.31593894958496, 70%, 80%); padding: 2px;\">man</span> <span style=\"color: black; background-color: hsl(217.1821117401123, 64%, 74%); padding: 2px;\">and</span> <span style=\"color: black; background-color: hsl(72.46830940246582, 74%, 84%); padding: 2px;\">##ere</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\">##n</span> <span style=\"color: black; background-color: hsl(117.6913833618164, 63%, 73%); padding: 2px;\">ve</span> <span style=\"color: black; background-color: hsl(81.51293277740479, 76%, 86%); padding: 2px;\">##rmi</span> <span style=\"color: black; background-color: hsl(99.60213661193848, 80%, 90%); padding: 2px;\">##tte</span> <span style=\"color: black; background-color: hsl(199.09286499023438, 60%, 70%); padding: 2px;\">##lt</span> <span style=\"color: black; background-color: hsl(253.3605194091797, 72%, 82%); padding: 2px;\">.</span> <span style=\"color: black; background-color: hsl(190.0482416152954, 79%, 89%); padding: 2px;\">[SEP]</span> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: white; padding: 20px;\"><h3 style=\"color: #3366cc; font-family: Arial, sans-serif;\">deepseek-ai/DeepSeek-Coder-V2-Instruct</h3><span style=\"color: black; background-color: hsl(162.91441440582275, 73%, 83%); padding: 2px;\">Die</span> <span style=\"color: black; background-color: hsl(262.40514278411865, 74%, 84%); padding: 2px;\">ein</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\">z</span> <span style=\"color: black; background-color: hsl(90.55755615234375, 78%, 88%); padding: 2px;\">ige</span> <span style=\"color: black; background-color: hsl(171.95903778076172, 75%, 85%); padding: 2px;\">We</span> <span style=\"color: black; background-color: hsl(181.00366115570068, 77%, 87%); padding: 2px;\">ishe</span> <span style=\"color: black; background-color: hsl(153.86983394622803, 71%, 81%); padding: 2px;\">it</span> <span style=\"color: black; background-color: hsl(108.64675998687744, 61%, 71%); padding: 2px;\">,</span> <span style=\"color: black; background-color: hsl(235.271315574646, 68%, 78%); padding: 2px;\">die</span> <span style=\"color: black; background-color: hsl(208.13748836517334, 62%, 72%); padding: 2px;\">man</span> <span style=\"color: black; background-color: hsl(253.3605194091797, 72%, 82%); padding: 2px;\">w</span> <span style=\"color: black; background-color: hsl(54.37910556793213, 70%, 80%); padding: 2px;\">ir</span> <span style=\"color: black; background-color: hsl(144.82521057128906, 69%, 79%); padding: 2px;\">kl</span> <span style=\"color: black; background-color: hsl(99.60213661193848, 80%, 90%); padding: 2px;\">ich</span> <span style=\"color: black; background-color: hsl(199.09286499023438, 60%, 70%); padding: 2px;\">bes</span> <span style=\"color: black; background-color: hsl(217.1821117401123, 64%, 74%); padding: 2px;\">itz</span> <span style=\"color: black; background-color: hsl(126.73596382141113, 65%, 75%); padding: 2px;\">t</span> <span style=\"color: black; background-color: hsl(108.64675998687744, 61%, 71%); padding: 2px;\">,</span> <span style=\"color: black; background-color: hsl(135.7805871963501, 67%, 77%); padding: 2px;\">ist</span> <span style=\"color: black; background-color: hsl(235.271315574646, 68%, 78%); padding: 2px;\">die</span> <span style=\"color: black; background-color: hsl(108.64675998687744, 61%, 71%); padding: 2px;\">,</span> <span style=\"color: black; background-color: hsl(235.271315574646, 68%, 78%); padding: 2px;\">die</span> <span style=\"color: black; background-color: hsl(208.13748836517334, 62%, 72%); padding: 2px;\">man</span> <span style=\"color: black; background-color: hsl(190.0482416152954, 79%, 89%); padding: 2px;\">and</span> <span style=\"color: black; background-color: hsl(81.51293277740479, 76%, 86%); padding: 2px;\">eren</span> <span style=\"color: black; background-color: hsl(117.6913833618164, 63%, 73%); padding: 2px;\">verm</span> <span style=\"color: black; background-color: hsl(72.46830940246582, 74%, 84%); padding: 2px;\">itt</span> <span style=\"color: black; background-color: hsl(244.31593894958496, 70%, 80%); padding: 2px;\">elt</span> <span style=\"color: black; background-color: hsl(226.22669219970703, 66%, 76%); padding: 2px;\">.</span> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color: white; padding: 20px;\"><h3 style=\"color: #3366cc; font-family: Arial, sans-serif;\">intfloat/multilingual-e5-large</h3><span style=\"color: black; background-color: hsl(54.37910556793213, 70%, 80%); padding: 2px;\"><s></span> <span style=\"color: black; background-color: hsl(90.55755615234375, 78%, 88%); padding: 2px;\">▁Die</span> <span style=\"color: black; background-color: hsl(153.86983394622803, 71%, 81%); padding: 2px;\">▁einzige</span> <span style=\"color: black; background-color: hsl(190.0482416152954, 79%, 89%); padding: 2px;\">▁We</span> <span style=\"color: black; background-color: hsl(126.73596382141113, 65%, 75%); padding: 2px;\">is</span> <span style=\"color: black; background-color: hsl(81.51293277740479, 76%, 86%); padding: 2px;\">heit</span> <span style=\"color: black; background-color: hsl(181.00366115570068, 77%, 87%); padding: 2px;\">,</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\">▁die</span> <span style=\"color: black; background-color: hsl(162.91441440582275, 73%, 83%); padding: 2px;\">▁man</span> <span style=\"color: black; background-color: hsl(99.60213661193848, 80%, 90%); padding: 2px;\">▁wirklich</span> <span style=\"color: black; background-color: hsl(135.7805871963501, 67%, 77%); padding: 2px;\">▁besitzt</span> <span style=\"color: black; background-color: hsl(181.00366115570068, 77%, 87%); padding: 2px;\">,</span> <span style=\"color: black; background-color: hsl(108.64675998687744, 61%, 71%); padding: 2px;\">▁ist</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\">▁die</span> <span style=\"color: black; background-color: hsl(181.00366115570068, 77%, 87%); padding: 2px;\">,</span> <span style=\"color: black; background-color: hsl(63.423686027526855, 72%, 82%); padding: 2px;\">▁die</span> <span style=\"color: black; background-color: hsl(162.91441440582275, 73%, 83%); padding: 2px;\">▁man</span> <span style=\"color: black; background-color: hsl(171.95903778076172, 75%, 85%); padding: 2px;\">▁anderen</span> <span style=\"color: black; background-color: hsl(144.82521057128906, 69%, 79%); padding: 2px;\">▁vermittelt</span> <span style=\"color: black; background-color: hsl(72.46830940246582, 74%, 84%); padding: 2px;\">.</span> <span style=\"color: black; background-color: hsl(117.6913833618164, 63%, 73%); padding: 2px;\"></s></span> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "german = \"\"\"Die einzige Weisheit, die man wirklich besitzt, ist die, die man anderen vermittelt.\"\"\"\n",
    "\n",
    "visualize_tokens(german, tokenizer_name=\"deepseek-ai/DeepSeek-R1\")\n",
    "visualize_tokens(german, tokenizer_name=\"google-bert/bert-base-uncased\")\n",
    "visualize_tokens(german, tokenizer_name=\"deepseek-ai/DeepSeek-Coder-V2-Instruct\")\n",
    "visualize_tokens(german, tokenizer_name=\"intfloat/multilingual-e5-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ollama and LLM hosting\n",
    "\n",
    "### 2.1 What is Ollama?\n",
    "\n",
    "Ollama is a platform designed to simplify the hosting and deployment of large language models, making it easier for developers to integrate powerful AI capabilities into their applications.\n",
    "\n",
    "To verify that Ollama is running properly, use the following command:\n",
    "\n",
    "```bash\n",
    "ollama -v\n",
    "```\n",
    "\n",
    "If the command doesn't return a version number, you'll need to start the Ollama server before proceeding.\n",
    "\n",
    "### 2.2 Hosting a Local LLM\n",
    "\n",
    "Below is an example demonstrating how to download and run Huggingface's [SmolLM2](https://huggingface.co/HuggingFaceTB/SmolLM2-360M-Instruct) locally on your PC.\n",
    "\n",
    "<img src=\"https://cdn-uploads.huggingface.co/production/uploads/61c141342aac764ce1654e43/oWWfzW4RbWkVIo7f-5444.png\" alt=\"SmolLM2 Image\" style=\"width:300px;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "\n",
    "MODEL = \"smollm2:360m\"\n",
    "# Initialize the Ollama client\n",
    "client = Client(host=\"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListResponse(models=[Model(model='smollm2:360m', modified_at=datetime.datetime(2025, 2, 28, 13, 13, 15, 71271, tzinfo=TzInfo(+01:00)), digest='297281b699fc51376006233ca400cd664c4f7b80ed88a47ef084f1e4b089803b', size=725566512, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='361.82M', quantization_level='F16')), Model(model='all-minilm:33m', modified_at=datetime.datetime(2025, 2, 27, 14, 30, 20, 377122, tzinfo=TzInfo(+01:00)), digest='4f5da3bd944d9ad1cd3acc7d065ee54367a4c703f51fb6295bd8bc5007ed0c4a', size=67319908, details=ModelDetails(parent_model='', format='gguf', family='bert', families=['bert'], parameter_size='33M', quantization_level='F16')), Model(model='qwen2.5-coder:0.5b-instruct-q4_K_M', modified_at=datetime.datetime(2025, 2, 27, 12, 56, 46, 212520, tzinfo=TzInfo(+01:00)), digest='b0b7a69e69028a52e977165edcfd1e5b23476bd8fcdb99c65add8d3e260ac0ce', size=397821474, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='494.03M', quantization_level='Q4_K_M')), Model(model='granite-embedding:278m', modified_at=datetime.datetime(2025, 2, 20, 14, 32, 34, 160306, tzinfo=TzInfo(+01:00)), digest='1a37926bf842899cbf90583e3932f3820548716d9d07661ba622199ffe95c552', size=562777301, details=ModelDetails(parent_model='', format='gguf', family='bert', families=['bert'], parameter_size='277.45M', quantization_level='F16')), Model(model='hf.co/ggml-org/jina-embeddings-v2-base-code-Q8_0-GGUF:latest', modified_at=datetime.datetime(2025, 2, 19, 14, 42, 14, 260350, tzinfo=TzInfo(+01:00)), digest='82c0781cc63c2f1cf55dc6a66e4364ffe5491f53c284c99ecf1830c52cf88b03', size=172869486, details=ModelDetails(parent_model='', format='gguf', family='jina-bert-v2', families=['jina-bert-v2'], parameter_size='160M', quantization_level='unknown')), Model(model='smollm:360m', modified_at=datetime.datetime(2025, 2, 12, 14, 48, 32, 768383, tzinfo=TzInfo(+01:00)), digest='b3ba1ccba2b80fe98c3b00798a95228d709b6ba86f15b483a4011b05fa2afe29', size=229131061, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='361.82M', quantization_level='Q4_0')), Model(model='smollm:135m', modified_at=datetime.datetime(2025, 2, 12, 13, 55, 38, 951189, tzinfo=TzInfo(+01:00)), digest='b0b2a46174385c0adcaa77ff245ffeced5fc4a61447b6f221b2beb5c5a760133', size=91739413, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='134.52M', quantization_level='Q4_0')), Model(model='deepseek-coder-v2:latest', modified_at=datetime.datetime(2024, 6, 27, 12, 21, 33, 6711, tzinfo=TzInfo(+02:00)), digest='8577f96d693e51135fb408f915344f4413db45ce31d771be6a6a9b1c7e7a4b40', size=8905125527, details=ModelDetails(parent_model='', format='gguf', family='deepseek2', families=['deepseek2'], parameter_size='15.7B', quantization_level='Q4_0'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the model and list the downloaded models\n",
    "client.pull(MODEL)\n",
    "client.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a text-based model for conversational AI, trained with the concept of language understanding and generation capabilities. I have been designed to process and respond to natural language inputs in a way that is understandable and helpful. I'm here to assist users like you by offering information on various topics through structured text input and providing clear responses when needed."
     ]
    }
   ],
   "source": [
    "# Your can now chat with the model by sending a message to the server. \n",
    "\n",
    "message = {\"role\": \"user\", \"content\": \"What are you?\"}\n",
    "\n",
    "for part in client.chat(model=MODEL, messages=[message], stream=True, keep_alive=30):\n",
    "    print(part[\"message\"][\"content\"], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Langchain and LLM Integration  \n",
    "\n",
    "<img src=\"https://opensource.muenchen.de/logo/langchain.jpg\" alt=\"Langchain Logo\" style=\"width:300px;\">  \n",
    "\n",
    "Langchain is a powerful framework that abstracts language model providers, allowing seamless integration of various LLMs, including:  \n",
    "\n",
    "- Ollama  \n",
    "- Claude  \n",
    "- OpenAI  \n",
    "\n",
    "In addition to model integration, Langchain offers a range of prebuilt components for common use cases, such as search and agent-based interactions.  \n",
    "\n",
    "To use Ollama with Langchain, simply utilize the `ChatOllama` class from the `langchain_ollama` package.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm a text-based AI language model. I can process and analyze written texts, including understanding context, detecting emotions, identifying patterns, and generating responses in various formats such as sentences or paragraphs.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "model = ChatOllama(model=MODEL ,base_url=\"http://localhost:11434\")\n",
    "\n",
    "messages = [SystemMessage(\"You are a helpfull assistant\"), HumanMessage(\"What are you?\")]\n",
    "\n",
    "result = model.invoke(messages)\n",
    "result.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Your Task: Chatbot with memory\n",
    "\n",
    "Use the [Automatic Message Management](https://python.langchain.com/docs/how_to/chatbots_memory/#automatic-history-management) to let your bot remember the conversation history. This will allow the bot to remember previous messages and respond accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# your code goes here\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    system_prompt = (\n",
    "        \"You are a helpful assistant. \"\n",
    "        \"Answer all questions to the best of your ability.\"\n",
    "    )\n",
    "    messages = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define the node and edge\n",
    "workflow.add_node(\"model\", call_model)\n",
    "workflow.add_edge(START, \"model\")\n",
    "\n",
    "# Add simple in-memory checkpointer\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here is a simple \"Hello, World!\" program written in Python:\n",
      "\n",
      "```python\n",
      "# Hello, World! Program\n",
      "print(\"Hello, World!\")\n",
      "```\n",
      "\n",
      "This code will output the following on your screen:\n",
      "\n",
      "```\n",
      "Hello, World!\n",
      "```\n",
      "\n",
      "If you want to print multiple lines, you can use a `for` loop and add newlines:\n",
      "\n",
      "```python\n",
      "# Hello, World! Program with printing multiple lines\n",
      "for i in range(3):\n",
      "    print(\"Hello, World!\")\n",
      "print(\"\\nThis is the third line\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Give me a hello world example in python\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}},\n",
    ")\n",
    "result['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You asked me to write a hello world example in Python. Here it is:\n",
      "\n",
      "```python\n",
      "# Hello, World! Program\n",
      "print(\"Hello, World!\")\n",
      "```\n",
      "\n",
      "I provided the code as an example of writing a \"Hello, World!\" program in Python, which prints \"Hello, World!\" followed by a newline at the end of the output.\n"
     ]
    }
   ],
   "source": [
    "result = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What did I just ask you?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}},\n",
    ")\n",
    "result['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Continue\n",
    "\n",
    "You can now use our [SmolLMV2](https://huggingface.co/HuggingFaceTB/SmolLM2-360M-Instruct) instance as the backend for the Continue plugin.\n",
    "\n",
    "To set it up, follow these steps:\n",
    "\n",
    "1. Open the Continue settings:  \n",
    "   ![](./media/continue/continue_settings.png) ![](./media/continue/continue_file.png)\n",
    "   \n",
    "2. Copy the contents of [`example_config.json`](./example_config.json).  \n",
    "\n",
    "3. Paste them into the \"Configuration\" file in Continue.\n",
    "\n",
    "Once configured, you should be able to use the chat functionality of the Continue plugin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Tab Auto Completions  \n",
    "\n",
    "To enable tab auto-completions (Ghost Tab) in your editor, you'll need to download a tab auto-completion model.  \n",
    "\n",
    "For this setup, we'll use the [Qwen2.5-Coder](https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF) model.  \n",
    "\n",
    "Once the model is downloaded, you should start seeing code completion suggestions directly in your editor.  \n",
    "\n",
    "<video width=\"480\" height=\"320\" controls>  \n",
    "  <source src=\"./media/continue/example.mp4\" type=\"video/mp4\">  \n",
    "</video>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProgressResponse(status='success', completed=None, total=None, digest=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ollama import Client\n",
    "\n",
    "#Download the model\n",
    "client = Client(host=\"http://localhost:11434\")\n",
    "client.pull(\"qwen2.5-coder:0.5b-instruct-q4_K_M\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2082750493.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    def fibonacci():\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# genrate fibonacci numbers up to a max of 500\n",
    "def fibonacci():"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
